{"title":"Clustering in Data Analytics","markdown":{"yaml":{"title":"Clustering in Data Analytics","author":"Sahil Sharma","date":"2023-11-07","categories":["Analysis","Visualization","Clustering"],"image":"clustering.png","jupyter":"python3"},"headingText":"Clustering Iris Data with K-Means Algorithm","containsRefs":false,"markdown":"\n\n\n\n\n### Introduction\n\nClustering is an unsupervised learning technique that groups data points together based on their similarities. It is a useful tool for exploring data and identifying patterns. The k-means algorithm is a popular clustering algorithm that works by assigning data points to a predefined number of clusters (k).\n\n### Why Clustering Matters ?\n \nClustering is a versatile tool used for a wide range of applications, including:\n\nCustomer segmentation: Clustering can be used to identify groups of customers with similar characteristics, enabling targeted marketing campaigns and personalized product recommendations.\n\nImage segmentation: Clustering can be used to segment images into different regions, such as identifying objects or segmenting tissues in medical imaging.\n\nAnomaly detection: Clustering can be used to identify outliers or anomalous data points that deviate from the typical patterns in the data.\n\nExploratory data analysis: Clustering can be used to explore and visualize the underlying structure and relationships within a dataset.\n\n### Common Clustering Algorithms\n\nNumerous clustering algorithms exist, each with its own strengths and limitations. Some popular clustering algorithms include:\n\nK-means clustering: This algorithm partitions the data into a predefined number of clusters (k) by iteratively assigning data points to the nearest cluster centroid.\n\nHierarchical clustering: This algorithm builds a hierarchy of clusters by recursively merging or splitting data points based on their similarity.\n\nDensity-based spatial clustering of applications with noise (DBSCAN): This algorithm identifies clusters based on the density of data points, marking outliers as points that lie in low-density regions.\n\nIn this blog post, we will use the k-means algorithm to cluster the Iris dataset. The Iris dataset is a popular benchmark dataset that consists of 150 samples of iris flowers, each belonging to one of three species: Iris setosa, Iris versicolor, and Iris virginica. Each sample is characterized by four features: sepal length, sepal width, petal length, and petal width.\n\n### Importing Libraries\n\nWe will need to import the following libraries into our Python script:\n\n```{python}\nimport pandas as pd\nfrom sklearn.cluster import KMeans\nfrom matplotlib import pyplot as plt\n```\n\n### Loading and Preprocessing Data\n\nWe will load the Iris dataset using pandas and preprocess the data by standardizing the features.\n\n### Load the Iris dataset\n```{python}\ndata = pd.read_csv('iris.csv')\n```\n\n### Preprocess the data\n```{python}\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ndata_scaled = scaler.fit_transform(data[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']])\n```\n\n### Clustering with K-Means\n\nWe will now use the k-means algorithm to cluster the data. We will set the number of clusters to three, as there are three species of iris flowers in the dataset.\n\n### Create a KMeans object with k=3 clusters\n```{python}\nkmeans = KMeans(n_clusters=3)\n```\n### Fit the KMeans model to the data\n```{python}\nkmeans.fit(data_scaled)\n```\n\n### Evaluating Clustering Results\n\nWe can evaluate the clustering results by calculating the silhouette score. The silhouette score is a measure of how well each data point is clustered.\n\n```{python}\nfrom sklearn.metrics import silhouette_score\n```\n\n### Calculate the silhouette score\n```{python}\nsilhouette_avg = silhouette_score(data_scaled, kmeans.labels_)\nprint('Silhouette score:', silhouette_avg)\n```\n\n### Vizualising CLusters\n\nWe can visualize the clusters by plotting the data points in two dimensions.\n\n```{python}\n# Extract the first two principal components\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=2)\npca_data = pca.fit_transform(data_scaled)\n\n# Plot the data points in two dimensions\nplt.scatter(pca_data[:, 0], pca_data[:, 1], c=kmeans.labels_)\nplt.title('Clustered Iris Data')\nplt.show()\n```\n\n\n### Conclusion\n\nIn this blog post, we have used the k-means algorithm to cluster the Iris dataset. We have also evaluated the clustering results and visualized the clusters. Clustering is a powerful tool for data exploration, pattern recognition, and group identification. By mastering clustering techniques, we can uncover hidden structures and relationships within data, gain valuable insights, and make informed decisions in various domains.\n\n**References**\n\n* [scikit-learn documentation](https://scikit-learn.org/stable/index.html)\n* [Iris dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/iris/)\n\n","srcMarkdownNoYaml":"\n\n\n# Clustering Iris Data with K-Means Algorithm\n\n\n### Introduction\n\nClustering is an unsupervised learning technique that groups data points together based on their similarities. It is a useful tool for exploring data and identifying patterns. The k-means algorithm is a popular clustering algorithm that works by assigning data points to a predefined number of clusters (k).\n\n### Why Clustering Matters ?\n \nClustering is a versatile tool used for a wide range of applications, including:\n\nCustomer segmentation: Clustering can be used to identify groups of customers with similar characteristics, enabling targeted marketing campaigns and personalized product recommendations.\n\nImage segmentation: Clustering can be used to segment images into different regions, such as identifying objects or segmenting tissues in medical imaging.\n\nAnomaly detection: Clustering can be used to identify outliers or anomalous data points that deviate from the typical patterns in the data.\n\nExploratory data analysis: Clustering can be used to explore and visualize the underlying structure and relationships within a dataset.\n\n### Common Clustering Algorithms\n\nNumerous clustering algorithms exist, each with its own strengths and limitations. Some popular clustering algorithms include:\n\nK-means clustering: This algorithm partitions the data into a predefined number of clusters (k) by iteratively assigning data points to the nearest cluster centroid.\n\nHierarchical clustering: This algorithm builds a hierarchy of clusters by recursively merging or splitting data points based on their similarity.\n\nDensity-based spatial clustering of applications with noise (DBSCAN): This algorithm identifies clusters based on the density of data points, marking outliers as points that lie in low-density regions.\n\nIn this blog post, we will use the k-means algorithm to cluster the Iris dataset. The Iris dataset is a popular benchmark dataset that consists of 150 samples of iris flowers, each belonging to one of three species: Iris setosa, Iris versicolor, and Iris virginica. Each sample is characterized by four features: sepal length, sepal width, petal length, and petal width.\n\n### Importing Libraries\n\nWe will need to import the following libraries into our Python script:\n\n```{python}\nimport pandas as pd\nfrom sklearn.cluster import KMeans\nfrom matplotlib import pyplot as plt\n```\n\n### Loading and Preprocessing Data\n\nWe will load the Iris dataset using pandas and preprocess the data by standardizing the features.\n\n### Load the Iris dataset\n```{python}\ndata = pd.read_csv('iris.csv')\n```\n\n### Preprocess the data\n```{python}\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ndata_scaled = scaler.fit_transform(data[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']])\n```\n\n### Clustering with K-Means\n\nWe will now use the k-means algorithm to cluster the data. We will set the number of clusters to three, as there are three species of iris flowers in the dataset.\n\n### Create a KMeans object with k=3 clusters\n```{python}\nkmeans = KMeans(n_clusters=3)\n```\n### Fit the KMeans model to the data\n```{python}\nkmeans.fit(data_scaled)\n```\n\n### Evaluating Clustering Results\n\nWe can evaluate the clustering results by calculating the silhouette score. The silhouette score is a measure of how well each data point is clustered.\n\n```{python}\nfrom sklearn.metrics import silhouette_score\n```\n\n### Calculate the silhouette score\n```{python}\nsilhouette_avg = silhouette_score(data_scaled, kmeans.labels_)\nprint('Silhouette score:', silhouette_avg)\n```\n\n### Vizualising CLusters\n\nWe can visualize the clusters by plotting the data points in two dimensions.\n\n```{python}\n# Extract the first two principal components\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=2)\npca_data = pca.fit_transform(data_scaled)\n\n# Plot the data points in two dimensions\nplt.scatter(pca_data[:, 0], pca_data[:, 1], c=kmeans.labels_)\nplt.title('Clustered Iris Data')\nplt.show()\n```\n\n\n### Conclusion\n\nIn this blog post, we have used the k-means algorithm to cluster the Iris dataset. We have also evaluated the clustering results and visualized the clusters. Clustering is a powerful tool for data exploration, pattern recognition, and group identification. By mastering clustering techniques, we can uncover hidden structures and relationships within data, gain valuable insights, and make informed decisions in various domains.\n\n**References**\n\n* [scikit-learn documentation](https://scikit-learn.org/stable/index.html)\n* [Iris dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/iris/)\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","theme":"cyborg","title-block-banner":true,"title":"Clustering in Data Analytics","author":"Sahil Sharma","date":"2023-11-07","categories":["Analysis","Visualization","Clustering"],"image":"clustering.png","jupyter":"python3"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}