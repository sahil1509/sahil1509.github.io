{
  "hash": "60b11d97dc2aff2231b3bcf678d9f90e",
  "result": {
    "markdown": "---\ntitle: Classification in Data Analytics\nauthor: Sahil Sharma\ndate: '2023-11-21'\ncategories:\n  - Analysis\n  - Visualization\n  - Classification\nimage: image.jpg\n---\n\n# Classifying Iris Flowers with Python: Exploring Floral Diversity\n\n## Introduction\n\nThe Iris dataset is a cornerstone of machine learning, offering insights into the diverse world of Iris flowers. In this blog post, we delve into the analysis of this dataset, focusing on classifying Iris flowers using Python's Scikit-learn library. Through visualization and classification techniques, we aim to unravel the patterns within this floral dataset.\n\n## Loading and Understanding the Iris Dataset\nThe analysis begins by loading the Iris dataset and converting it into a Pandas DataFrame. This step enables us to gain a comprehensive understanding of the dataset's structure, featuring essential characteristics like Sepal Length, Sepal Width, Petal Length, and Petal Width.\n\n## Data Preparation\nData preparation involves splitting the dataset into training and testing sets, ensuring that the classification models are trained on one subset and evaluated on another. This step sets the stage for training the classification model.\n\n## Classification using K-Nearest Neighbors (KNN)\nImplementing the K-Nearest Neighbors classifier, we train the model using the training data and subsequently make predictions on the test data. Calculating the accuracy score and generating a classification report allows us to assess the model's performance.\n\n## Visualization of Classification Results\nVisualizing the predicted classes on a scatter plot based on Sepal Length and Sepal Width provides a tangible representation of the model's classification output. This visualization aids in understanding how well the model distinguishes between different Iris species based on these two features.\n\n## Insights from the Analysis\nThe accuracy score and classification report shed light on the model's performance, while the scatter plot visualization offers a glimpse into the separability of Iris species based on Sepal Length and Width.\n\n## Implementation\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nimport matplotlib.pyplot as plt\n\n# Load Iris dataset\niris = load_iris()\n\n# Create a DataFrame from the Iris dataset\niris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\niris_df['target'] = iris.target\n\n# Split the data into features (X) and target variable (y)\nX = iris_df.drop('target', axis=1)\ny = iris_df['target']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize the K-Nearest Neighbors classifier\nknn = KNeighborsClassifier(n_neighbors=3)\n\n# Train the classifier\nknn.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = knn.predict(X_test)\n\n# Calculate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'Accuracy: {accuracy:.2f}')\n\n# Generate classification report\nprint(classification_report(y_test, y_pred, target_names=iris.target_names))\n\n# Visualizing the results\nplt.figure(figsize=(8, 6))\n\n# Scatter plot for feature comparison\nplt.scatter(X_test.iloc[:, 0], X_test.iloc[:, 1], c=y_pred, cmap='viridis', edgecolor='k')\nplt.xlabel('Sepal Length')\nplt.ylabel('Sepal Width')\nplt.title('Predicted Classes')\nplt.colorbar(label='Class')\nplt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAccuracy: 1.00\n              precision    recall  f1-score   support\n\n      setosa       1.00      1.00      1.00        10\n  versicolor       1.00      1.00      1.00         9\n   virginica       1.00      1.00      1.00        11\n\n    accuracy                           1.00        30\n   macro avg       1.00      1.00      1.00        30\nweighted avg       1.00      1.00      1.00        30\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-2-output-2.png){width=654 height=523}\n:::\n:::\n\n\n## Conclusion\n\nIn conclusion, this analysis showcases how Python, along with Scikit-learn, facilitates the exploration and classification of floral diversity using the Iris dataset. It provides a valuable introduction to classification techniques and serves as a foundation for further analysis and exploration in the realm of machine learning and botanical studies.\n\nThrough this exploration, we've touched upon the fundamentals of analyzing the Iris dataset, highlighting the beauty and complexity of floral diversity encapsulated within this classic dataset.\n\nThis blog post encapsulates the analysis performed on the Iris dataset, showcasing classification techniques and visualizations using Python. It serves as a comprehensive guide for enthusiasts keen on exploring the intricate world of Iris flowers through data analysis and machine learning.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}